{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision import *\n",
    "from torchvision.models import *\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Your_path_to_models_folder = '/media/trevor/main-storag/master_classes/big_data_health/BDH_project' # exclude '/models'\n",
    "\n",
    "Your_path_to_dataset = '/media/trevor/main-storag/CheXpert-v1.0-small' # '......./CheXpert-v1.0-small' includes '/CheXpert-v1.0-small'\n",
    "Your_main_path = '/media/trevor/main-storag' # dir contains CheXpert-v1.0-small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = 'u_zeros' # change to one of u_ignore, u_zeros, u_ones, u_multiclass, u_sefltrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "chestxrays_root = Path(Your_main_path)\n",
    "data_path = chestxrays_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_train_df = pd.read_csv(Your_path_to_dataset + '/train.csv')\n",
    "full_valid_df = pd.read_csv(Your_path_to_dataset + '/valid.csv')\n",
    "full_train_df['train_valid'] = False\n",
    "full_valid_df['train_valid'] = True\n",
    "full_df = pd.concat([full_train_df, full_valid_df])\n",
    "full_df = full_df.reset_index(drop=True)\n",
    "\n",
    "full_train_df['patient'] = full_train_df.Path.str.split('/',3,True)[2]\n",
    "full_train_df  ['study'] = full_train_df.Path.str.split('/',4,True)[3]\n",
    "\n",
    "full_valid_df['patient'] = full_valid_df.Path.str.split('/',3,True)[2]\n",
    "full_valid_df  ['study'] = full_valid_df.Path.str.split('/',4,True)[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "chexnet_targets = ['No Finding',\n",
    "       'Enlarged Cardiomediastinum', 'Cardiomegaly', 'Lung Opacity',\n",
    "       'Lung Lesion', 'Edema', 'Consolidation', 'Pneumonia', 'Atelectasis',\n",
    "       'Pneumothorax', 'Pleural Effusion', 'Pleural Other', 'Fracture',\n",
    "       'Support Devices']\n",
    "\n",
    "chexpert_targets = ['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Pleural Effusion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_string_u_multiclass(row):\n",
    "    feature_list = []\n",
    "    for feature in chexpert_targets:\n",
    "        # if 1 then has the feature\n",
    "        if row[feature] == 1:\n",
    "            feature_list.append(feature+'_p')\n",
    "        # if -1 then add ''_u to the feature\n",
    "        elif row[feature] == -1:\n",
    "            feature_list.append(feature+'_u')\n",
    "        elif row[feature] == 0:\n",
    "            feature_list.append(feature+'_n')\n",
    "            \n",
    "    return ';'.join(feature_list)\n",
    "\n",
    "def feature_string_u_binary(row):\n",
    "    feature_list = []\n",
    "    for feature in u_one_features:\n",
    "        if row[feature] in [-1,1]:\n",
    "            feature_list.append(feature)\n",
    "            \n",
    "    for feature in u_zero_features:\n",
    "        if row[feature] == 1:\n",
    "            feature_list.append(feature)\n",
    "            \n",
    "    return ';'.join(feature_list)\n",
    "\n",
    "# Determine the labels of the sample\n",
    "def feature_string_u_ignore(row):\n",
    "    feature_list = []\n",
    "    for feature in chexpert_targets:\n",
    "        # if 1 then has the feature\n",
    "        if row[feature] == 1:\n",
    "            feature_list.append(feature+'_p')\n",
    "        elif row[feature] == 0:\n",
    "            feature_list.append(feature+'_n')\n",
    "            \n",
    "    return ';'.join(feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_src(df = full_df):\n",
    "    return (ImageList\n",
    "        .from_df(df, data_path, 'Path')\n",
    "        .split_from_df('train_valid')\n",
    "        .label_from_df('feature_string',label_delim=';')\n",
    "       )\n",
    "def get_data(size, src, bs=32):\n",
    "    return (src.transform(get_transforms(do_flip=False), size=size, padding_mode='zeros')\n",
    "        .databunch(bs=bs).normalize(imagenet_stats))\n",
    "def get_preds_per_study():\n",
    "    valid_preds=learn.get_preds(ds_type=DatasetType.Valid)[0]\n",
    "   \n",
    "    for i, c in enumerate(learn.data.classes):\n",
    "        full_valid_df[c] = valid_preds[:,i]\n",
    "    \n",
    "    return full_valid_df.groupby(['patient','study'])[learn.data.classes].max().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_onehot(df):\n",
    "    for c in u_targets:\n",
    "        df[c] = [None]*len(df)\n",
    "    for idx,r in df.iterrows():\n",
    "        for c in chexpert_targets:\n",
    "            if r[c] == -1:\n",
    "                df.loc[idx,c+'_u'] = 1\n",
    "                df.loc[idx,c+'_p'] = 0\n",
    "                df.loc[idx,c+'_n'] = 0\n",
    "            elif r[c] == 1:\n",
    "                df.loc[idx,c+'_u'] = 0\n",
    "                df.loc[idx,c+'_p'] = 1\n",
    "                df.loc[idx,c+'_n'] = 0\n",
    "            elif r[c] == 0:\n",
    "                df.loc[idx,c+'_u'] = 0\n",
    "                df.loc[idx,c+'_p'] = 0\n",
    "                df.loc[idx,c+'_n'] = 1\n",
    "            else:\n",
    "                df.loc[idx,c+'_u'] = 0\n",
    "                df.loc[idx,c+'_p'] = 0\n",
    "                df.loc[idx,c+'_n'] = 0\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binary cases\n",
    "def validation_eval_binary(learn):\n",
    "    acts = full_valid_df.groupby(['patient','study'])[learn.data.classes].max().values\n",
    "\n",
    "    valid_preds=learn.get_preds(ds_type=DatasetType.Valid)\n",
    "    preds = valid_preds[0]\n",
    "    preds_df = full_valid_df.copy()\n",
    "\n",
    "    for i, c in enumerate(learn.data.classes):\n",
    "        preds_df[c] = preds[:,i]\n",
    "\n",
    "    preds = preds_df.groupby(['patient','study'])[learn.data.classes].max().values\n",
    "\n",
    "    auc_scores = {data.classes[i]: roc_auc_score(acts[:,i],preds[:,i]) for i in range(len(chexpert_targets))}\n",
    "\n",
    "    #average results reported in the associated paper\n",
    "    chexpert_auc_scores = {'Atelectasis':      0.858,\n",
    "                           'Cardiomegaly':     0.854,\n",
    "                           'Consolidation':    0.939,\n",
    "                           'Edema':            0.941,\n",
    "                           'Pleural Effusion': 0.936}\n",
    "\n",
    "    max_feat_len = max(map(len, chexpert_targets))\n",
    "\n",
    "    avg_chexpert_auc = sum(list(chexpert_auc_scores.values()))/len(chexpert_auc_scores.values())\n",
    "    avg_auc          = sum(list(auc_scores.values()))/len(auc_scores.values())\n",
    "\n",
    "    [print(f'{k: <{max_feat_len}}\\t auc: {auc_scores[k]:.3}\\t chexpert auc: {chexpert_auc_scores[k]:.3}\\t difference:\\\n",
    "    {(chexpert_auc_scores[k]-auc_scores[k]):.3}') for k in chexpert_targets]\n",
    "\n",
    "    print(f'\\nAverage auc: {avg_auc:.3} \\t CheXpert average auc {avg_chexpert_auc:.3}\\t Difference {(avg_chexpert_auc-avg_auc):.3}')\n",
    "    \n",
    "    return avg_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiclass case\n",
    "def validation_eval_multi(learn):\n",
    "    # unlike using u_1 and u_0, we need extra classes for binary auc_roc_score\n",
    "    # we will using similiar strategy as 'one_hot_encoding'\n",
    "    acts = get_df_onehot(full_valid_df)\n",
    "    \n",
    "    # model_classes_pred = [x for x in learn.data.classes if x in chexpert_targets]\n",
    "    acts = full_valid_df.groupby(['patient','study'])[learn.data.classes].max().values\n",
    "\n",
    "    valid_preds=learn.get_preds(ds_type=DatasetType.Valid)\n",
    "    preds = valid_preds[0]\n",
    "    preds_df = full_valid_df.copy()\n",
    "\n",
    "    for i, c in enumerate(learn.data.classes):\n",
    "        preds_df[c] = preds[:,i]\n",
    "\n",
    "    preds = preds_df.groupby(['patient','study'])[learn.data.classes].max().values\n",
    "    \n",
    "    auc_scores = {}\n",
    "    \n",
    "    for i in range(len(learn.data.classes)):\n",
    "        # handel only one class case\n",
    "        try:\n",
    "            score = roc_auc_score(acts[:,i],preds[:,i])\n",
    "        except ValueError:\n",
    "            n_acts = acts[:,i]\n",
    "            n_acts = np.append(n_acts,0)\n",
    "            n_acts = np.append(n_acts,1)\n",
    "            n_preds = preds[:,i]\n",
    "            n_preds = np.append(n_preds,0)\n",
    "            n_preds = np.append(n_preds,1)\n",
    "            print(n_acts)\n",
    "            score = roc_auc_score(n_acts,n_preds)\n",
    "        auc_scores[learn.data.classes[i]] = score\n",
    "    print(auc_scores)\n",
    "\n",
    "#     #average results reported in the associated paper\n",
    "#     chexpert_auc_scores = {'Atelectasis':      0.858,\n",
    "#                            'Cardiomegaly':     0.854,\n",
    "#                            'Consolidation':    0.939,\n",
    "#                            'Edema':            0.941,\n",
    "#                            'Pleural Effusion': 0.936}\n",
    "\n",
    "#     max_feat_len = max(map(len, chexpert_targets))\n",
    "\n",
    "#     avg_chexpert_auc = sum(list(chexpert_auc_scores.values()))/len(chexpert_auc_scores.values())\n",
    "    avg_auc = sum(list(auc_scores.values()))/len(auc_scores.values())\n",
    "\n",
    "    [print(f'auc: {auc_scores[k]:.3}\\t') for k in u_multi_targets]\n",
    "\n",
    "    print(f'\\nAverage auc: {avg_auc:.3} \\t')\n",
    "    \n",
    "    return avg_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MODEL == 'u_multiclass':\n",
    "    u_targets = ['Atelectasis_u', 'Cardiomegaly_u', 'Consolidation_u', 'Edema_u', 'Pleural Effusion_u']\n",
    "    p_targets = ['Atelectasis_p', 'Cardiomegaly_p', 'Consolidation_p', 'Edema_p', 'Pleural Effusion_p']\n",
    "    n_targets = ['Atelectasis_n', 'Cardiomegaly_n', 'Consolidation_n', 'Edema_n', 'Pleural Effusion_n']\n",
    "    u_multi_targets = u_targets + p_targets + n_targets\n",
    "    full_df['feature_string'] = full_df.apply(feature_string_u_multiclass,axis = 1).fillna('')\n",
    "elif MODEL == 'u_zeros':\n",
    "    u_one_features = []\n",
    "    u_zero_features = ['Atelectasis', 'Edema','Cardiomegaly', 'Consolidation', 'Pleural Effusion']\n",
    "    full_df['feature_string'] = full_df.apply(feature_string_u_binary,axis = 1).fillna('')\n",
    "elif MODEL == 'u_ones':\n",
    "    u_one_features = ['Atelectasis', 'Edema','Cardiomegaly', 'Consolidation', 'Pleural Effusion']\n",
    "    u_zero_features = []\n",
    "    full_df['feature_string'] = full_df.apply(feature_string_u_binary,axis = 1).fillna('')\n",
    "else:\n",
    "    u_targets = []\n",
    "    p_targets = ['Atelectasis_p', 'Cardiomegaly_p', 'Consolidation_p', 'Edema_p', 'Pleural Effusion_p']\n",
    "    n_targets = ['Atelectasis_n', 'Cardiomegaly_n', 'Consolidation_n', 'Edema_n', 'Pleural Effusion_n']\n",
    "    u_multi_targets = u_targets + p_targets + n_targets\n",
    "    full_df['feature_string'] = full_df.apply(feature_string_u_ignore,axis = 1).fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CheXpertEvalCallback(LearnerCallback):\n",
    "    def __init__(self, learn):\n",
    "        super().__init__(learn)\n",
    "        self.skip = False\n",
    "        self.avg_auc = 0\n",
    "    def on_epoch_end(self,**kwargs):\n",
    "        if self.skip: return\n",
    "        self.avg_auc = validation_eval(self.learn)\n",
    "class SaveCallback(LearnerCallback):\n",
    "    _order = 99\n",
    "    def __init__(self, learn):\n",
    "        super().__init__(learn)\n",
    "        self.epoch = 0\n",
    "        self.skip = False\n",
    "    def on_epoch_end(self, **kwargs):\n",
    "        self.epoch += 1\n",
    "cbfs = [CheXpertEvalCallback, SaveCallback]\n",
    "def lr_find_no_cbs(learn):\n",
    "    learn.callback_fns = [cbf for cbf in learn.callback_fns if cbf not in cbfs]\n",
    "    lr_find(learn)\n",
    "    learn.recorder.plot(suggestion=True)\n",
    "    learn.callback_fns += cbfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 224\n",
    "data = get_data(img_size, get_src(full_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/media/trevor/main-storag/master_classes/big_data_health/BDH_project/u_zeros.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-4f0dfe9bc1bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# learn = load_learner(Path(Your_path_to_models_folder)/'models',MODEL+'.pkl')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlearn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcnn_learner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdensenet121\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback_fns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcbfs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mYour_path_to_models_folder\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mMODEL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, file, device, strict, with_opt, purge, remove_module)\u001b[0m\n\u001b[1;32m    263\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0msource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34mf'{file}.pth'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_pathlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m         \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'opt'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m             \u001b[0mmodel_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module)\u001b[0m\n\u001b[1;32m    364\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0mnew_fd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/media/trevor/main-storag/master_classes/big_data_health/BDH_project/u_zeros.pth'"
     ]
    }
   ],
   "source": [
    "# learn = load_learner(Path(Your_path_to_models_folder)/'models',MODEL+'.pkl')\n",
    "learn = cnn_learner(data, densenet121, callback_fns=cbfs)\n",
    "learn.load(Your_path_to_models_folder + '/models/' + MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MODEL == 'u_multiclass':\n",
    "    print(validation_eval_multi(learn))\n",
    "elif MODEL == 'u_zeros':\n",
    "    print(validation_eval_binary(learn))\n",
    "elif MODEL == 'u_ones':\n",
    "    print(validation_eval_binary(learn))\n",
    "else:\n",
    "    print(validation_eval_multi(learn))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
